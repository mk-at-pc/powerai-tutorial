{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a proof-of-concept (POC) machine learning model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Create a machine learning model capable of predicting the correct validity of a meter reading. The model will be user to take over decision-making currently applied by a user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "### 1. Conception\n",
    "\n",
    "- Answer questions:\n",
    "    - How is the current process of validity check by the user?\n",
    "    - Which **data** does the user use to make the decision?\n",
    "    - Where do I find this **data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Acquire Data\n",
    "\n",
    "- Get access to DBs providing **data**\n",
    "- Write SQLs to access **data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here only single csv: In reality as set of DB resources\n",
    "data = pandas.read_csv(\"./data/readings.csv\", index_col=0) \\\n",
    "             .sort_values(by=\"readAt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractId</th>\n",
       "      <th>valid</th>\n",
       "      <th>validityChangedAt</th>\n",
       "      <th>readAt</th>\n",
       "      <th>value</th>\n",
       "      <th>priority</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>origin</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>reason</th>\n",
       "      <th>param</th>\n",
       "      <th>code</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>4443</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-07 13:38:34</td>\n",
       "      <td>2018-09-25 00:00:00</td>\n",
       "      <td>12496.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2018-09-25 18:41:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>7796478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>9857</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-18 11:50:06</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-18 11:50:06</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>89913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>5905</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-08 06:30:07</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>22925.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-08 06:30:07</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>3322005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-14 16:25:32</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>32376.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-11-14 16:25:32</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>470000340043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-13 06:05:24</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>32376.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-11-13 06:05:24</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>470000340043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>3918</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27 09:11:56</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>12057.6</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 09:11:56</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>1APADA90917567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>4159</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-27 09:07:24</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 09:07:24</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-0:1.8.0</td>\n",
       "      <td>1LOG0065083099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9019</th>\n",
       "      <td>6111</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-27 09:24:57</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>44501.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2020-03-27 09:24:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>4100186942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11165</th>\n",
       "      <td>3227</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-28 00:10:37</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>33260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2020-03-28 00:10:37</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>889902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020</th>\n",
       "      <td>6111</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27 10:51:34</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>44501.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 10:51:34</td>\n",
       "      <td>COT</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>4100186942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16526 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contractId  valid    validityChangedAt               readAt    value  \\\n",
       "6164         4443      0  2020-01-07 13:38:34  2018-09-25 00:00:00  12496.0   \n",
       "9487         9857      0  2018-10-18 11:50:06  2018-10-01 00:00:00     36.0   \n",
       "9359         5905      1  2018-10-08 06:30:07  2018-10-01 00:00:00  22925.0   \n",
       "9354          393      0  2018-11-14 16:25:32  2018-10-01 00:00:00  32376.0   \n",
       "9353          393      0  2018-11-13 06:05:24  2018-10-01 00:00:00  32376.0   \n",
       "...           ...    ...                  ...                  ...      ...   \n",
       "4596         3918      0  2020-03-27 09:11:56  2020-03-26 23:59:59  12057.6   \n",
       "13637        4159      1  2020-03-27 09:07:24  2020-03-26 23:59:59   2561.0   \n",
       "9019         6111      1  2020-03-27 09:24:57  2020-03-27 23:59:59  44501.0   \n",
       "11165        3227      0  2020-03-28 00:10:37  2020-03-27 23:59:59  33260.0   \n",
       "9020         6111      0  2020-03-27 10:51:34  2020-03-27 23:59:59  44501.0   \n",
       "\n",
       "       priority  qualifier    origin            createdAt reason param  \\\n",
       "6164          2       read  customer  2018-09-25 18:41:11    NaN   NaN   \n",
       "9487          3  estimated       vnb  2018-10-18 11:50:06    COS   SMV   \n",
       "9359          1       read       vnb  2018-10-08 06:30:07    COS   SMV   \n",
       "9354          3  estimated       vnb  2018-11-14 16:25:32    COS   SMV   \n",
       "9353          3  estimated       vnb  2018-11-13 06:05:24    COS   SMV   \n",
       "...         ...        ...       ...                  ...    ...   ...   \n",
       "4596          1       read       msb  2020-03-27 09:11:56    PMR   MRV   \n",
       "13637         1       read       msb  2020-03-27 09:07:24    PMR   MRV   \n",
       "9019          2       read  customer  2020-03-27 09:24:57    NaN   NaN   \n",
       "11165         1       read       vnb  2020-03-28 00:10:37    PMR   MRV   \n",
       "9020          1       read       msb  2020-03-27 10:51:34    COT   MRV   \n",
       "\n",
       "             code         counter  \n",
       "6164    1-1:1.8.0         7796478  \n",
       "9487   7-20:3.0.0           89913  \n",
       "9359   7-20:3.0.0         3322005  \n",
       "9354    1-1:1.8.0    470000340043  \n",
       "9353    1-1:1.8.0    470000340043  \n",
       "...           ...             ...  \n",
       "4596    1-1:1.8.0  1APADA90917567  \n",
       "13637   1-0:1.8.0  1LOG0065083099  \n",
       "9019    1-1:1.8.0      4100186942  \n",
       "11165  7-20:3.0.0          889902  \n",
       "9020    1-1:1.8.0      4100186942  \n",
       "\n",
       "[16526 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze data\n",
    "\n",
    "- What is the meaning of individual columns?\n",
    "- Columns suitable for decision-making? (e.g. too many na-values bad)\n",
    "- Is **data** assumed to be sufficient? If not, start over with **1. Conception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# E.g. check total number of valid / invalid readings, 1 or 0, respectively. \n",
    "# [TASK]: Check number of valid / invalid entries in data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Data Aggregation Strategy\n",
    "\n",
    "How to group **data** belonging together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by contract, code and counter\n",
    "# [TASK]: Define grouper list based on items belonging together\n",
    "grouper = [...]\n",
    "select = [column for column in data if not column in grouper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = list(group[select] for context, group in data.groupby(grouper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated[102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Structure and clean data\n",
    "\n",
    "- Structure **data** so you have a clear view how to clean it\n",
    "- Clean data: Remove insufficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose past readings from readings for assessment\n",
    "past = []\n",
    "assess = []\n",
    "for x in aggregated:\n",
    "    \n",
    "    # Last item of the row\n",
    "    assess_ = x.iloc[-1]\n",
    "    \n",
    "    # Append n-1 rows from group\n",
    "    past_ = x.iloc[0:-1]\n",
    "    \n",
    "    # [TASK] : Mask data not available @ assess_[\"createdAt\"]\n",
    "    # Hmm ... unfortunately if have to drop some values\n",
    "    # that have not been available @ decision making time\n",
    "    ...\n",
    "    \n",
    "    # -> Problem with DB updates! ...\n",
    "    \n",
    "    past.append(past_)\n",
    "    assess.append(assess_)\n",
    "    \n",
    "past[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # Features for predicting\n",
    "y = []\n",
    "\n",
    "select.remove(\"valid\")\n",
    "for past_, assess_ in zip(past, assess):\n",
    "    X.append(assess_[select].tolist() + past_[::-1].values.flatten().tolist())\n",
    "    y.append(assess_[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix shape of X: padding of individual # of past items\n",
    "n_features = 3 * (len(select) + 1) + len(select)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Create training data\n",
    "\n",
    "- Decompose data into feature matrix X and target vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix needs to be 2D in this case. Since # of past readings varies,\n",
    "# some data points need to be dropped, some other need to be padded (with na)\n",
    "Xout = []\n",
    "for Xi in X:\n",
    "    \n",
    "    n = len(Xi)\n",
    "\n",
    "    # [TASK] : Modify elements in Xi such that list have n_features elements\n",
    "    ...\n",
    "    \n",
    "    Xout.append(Xi)\n",
    "\n",
    "# Feature matrix: Features characterizing the past reading history\n",
    "X = pandas.DataFrame(Xout) \n",
    "# Target vector: Binary vector (1 -> valid, 0 -> invalid)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preparation for machine learning: Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conversion: Features must be floats. Think of how to convert\n",
    "    - dates\n",
    "    - strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn: Library containing a greate number of ML utilities\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion for filtering float-like columns from x\n",
    "def is_float_convertable(x):\n",
    "    \n",
    "    try: \n",
    "        x.astype(float)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Criterion for filtering date-like columns from x\n",
    "def is_datelike(x):\n",
    "    \n",
    "    try:\n",
    "        pandas.to_datetime(x)\n",
    "        \n",
    "        if not is_float_convertable(x):\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously, we have multi-type data available. All types have to be converted into float. \n",
    "# For converting categorical data, there are special encoding methodes available. \n",
    "\n",
    "# Decompose data by type\n",
    "numerical = [column for column in X if is_float_convertable(X[column])]\n",
    "dates = [column for column in X if is_datelike(X[column])]\n",
    "strings = [column for column in X if not column in numerical + dates]\n",
    "\n",
    "# [TASK] Convert dates to float: Total seconds since millenium\n",
    "null_date = datetime.datetime(2000, 1, 1)\n",
    "...\n",
    "    \n",
    "# Convert str columns: One-Hot-Encoding\n",
    "Xstr = X[strings].fillna(\"nan\")\n",
    "Xstr = pandas.DataFrame(OneHotEncoder(sparse=False) \\\n",
    "             .fit_transform(Xstr))\n",
    "X.drop(columns=strings, inplace=True)\n",
    "X.columns = range(len(X.columns))\n",
    "string_columns = np.arange(max(X.columns) + 1, (max(X.columns) + Xstr.shape[1] + 1))\n",
    "X[string_columns] = Xstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- na-fill strategy: Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SimpleImputer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling: Normalize **data** features, such that each have similar impact, e.g. (-1, 1) normalization of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training\n",
    "\n",
    "- Select suitable algorithm\n",
    "- Test if training technically works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn: Library containing a greate number of ML utilities\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Data splitting: Given subset of X, train to be able to predict associated subset y\n",
    "# [TASK] : Train using the first 2300 data points ...\n",
    "tree.fit(X[...], y[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier prediction for data NOT used for training\n",
    "# [TASK] ... and predict target for the res\n",
    "pred = tree.predict(X[...])\n",
    "true = y[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measure quality of model: Precision and Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(pred, true, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Systematic optimization\n",
    "\n",
    "- Algorithms have parameters to be choosen by user: Apply optimization\n",
    "- Split data systematically among different configurations and select the \"best\" model (requires definition of metric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters taken by DecisionTree classifier\n",
    "params = {\"max_depth\" : [None, 5, 10, 20, 50],\n",
    "          \"min_samples_split\" : [2, 5, 10],\n",
    "          \"max_features\" : [\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "# Create data split strategy\n",
    "cv = KFold(5, random_state=42, shuffle=True)\n",
    "\n",
    "# Init grid search for optimum parameters\n",
    "grd = GridSearchCV(tree, params, cv=cv, scoring=\"precision\")\n",
    "\n",
    "# Train on all possible combinations of parameters\n",
    "grd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best classifier\n",
    "clf = grd.best_estimator_\n",
    "\n",
    "# Total precision\n",
    "grd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total score\n",
    "confusion = []\n",
    "for train, test in cv.split(X): # Provides arrays of indices\n",
    "    \n",
    "    # [TASK] : \"fit clf\" using train and \"pred\" using test indices\n",
    "    clf.fit(X[...], y[...])\n",
    "    pred = clf.predict(X[...])\n",
    "    confusion.append(confusion_matrix(pred, y[...], labels=[1, 0]))\n",
    "    \n",
    "confusion = np.array(confusion).sum(axis=0)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Bring to application\n",
    "\n",
    "- Transformer implement: Implement custom preprocessing into transformer class object\n",
    "- Transformer chain: Chain all processing and classification items together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer object: Steps 4. and 5. in one class \n",
    "from utils import CustomPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer chain\n",
    "chain = Pipeline([(\"custom\", CustomPreprocessing()),\n",
    "                  (\"fillna\", SimpleImputer()),\n",
    "                  (\"scale\", RobustScaler()),\n",
    "                  (\"clf\", DecisionTreeClassifier(**clf.get_params()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on complete data set\n",
    "chain.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data from application:\n",
    "file = 1 # Choose from 1 or 2\n",
    "# Two counters belonging to a single contract\n",
    "appl_data = pandas.read_csv(f\"./data/readings_application_{file}.csv\", index_col=0) \\\n",
    "             .sort_values(by=\"readAt\") \\\n",
    "            [data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict validity of readings with valid == nan\n",
    "# [TASK] : Apply predict on appl_data\n",
    "pred = chain.predict(...)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
