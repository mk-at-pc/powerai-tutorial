{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a proof-of-concept (POC) machine learning model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This training notebook provides\n",
    "- a low level introduction into the basic steps when setting up a POC machine learning model\n",
    "- an impression of the effort of individual steps\n",
    "- explains expressions frequently used like\n",
    "    - Model preprocessing including\n",
    "        - Transformer\n",
    "        - Transformer chain\n",
    "    - Model training\n",
    "        - Classifier\n",
    "    - Model evaluation\n",
    "        - Splitting for training and testing\n",
    "    - Model prediction (application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Create a machine learning model capable of predicting the correct validity of a meter reading. The model will be user to take over decision-making currently applied by a user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "### 1. Conception\n",
    "\n",
    "- Answer questions:\n",
    "    - How is the current process of validity check by the user?\n",
    "    - Which **data** does the user use to make the decision?\n",
    "    - Where do I find this **data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Acquire Data\n",
    "\n",
    "- Get access to DBs providing **data**\n",
    "- Write SQLs to access **data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here only single csv: In reality as set of DB resources\n",
    "data = pandas.read_csv(\"./data/readings.csv\", index_col=0) \\\n",
    "             .sort_values(by=\"readAt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractId</th>\n",
       "      <th>valid</th>\n",
       "      <th>validityChangedAt</th>\n",
       "      <th>readAt</th>\n",
       "      <th>value</th>\n",
       "      <th>priority</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>origin</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>reason</th>\n",
       "      <th>param</th>\n",
       "      <th>code</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>4443</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-07 13:38:34</td>\n",
       "      <td>2018-09-25 00:00:00</td>\n",
       "      <td>12496.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2018-09-25 18:41:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>7796478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>9857</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-18 11:50:06</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-18 11:50:06</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>89913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>5905</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-08 06:30:07</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>22925.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-08 06:30:07</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>3322005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-14 16:25:32</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>32376.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-11-14 16:25:32</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>470000340043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-13 06:05:24</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>32376.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-11-13 06:05:24</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>470000340043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>3918</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27 09:11:56</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>12057.6</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 09:11:56</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>1APADA90917567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>4159</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-27 09:07:24</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 09:07:24</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-0:1.8.0</td>\n",
       "      <td>1LOG0065083099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9019</th>\n",
       "      <td>6111</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-27 09:24:57</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>44501.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2020-03-27 09:24:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>4100186942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11165</th>\n",
       "      <td>3227</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-28 00:10:37</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>33260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2020-03-28 00:10:37</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "      <td>7-20:3.0.0</td>\n",
       "      <td>889902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020</th>\n",
       "      <td>6111</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27 10:51:34</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>44501.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>msb</td>\n",
       "      <td>2020-03-27 10:51:34</td>\n",
       "      <td>COT</td>\n",
       "      <td>MRV</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>4100186942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16526 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contractId  valid    validityChangedAt               readAt    value  \\\n",
       "6164         4443      0  2020-01-07 13:38:34  2018-09-25 00:00:00  12496.0   \n",
       "9487         9857      0  2018-10-18 11:50:06  2018-10-01 00:00:00     36.0   \n",
       "9359         5905      1  2018-10-08 06:30:07  2018-10-01 00:00:00  22925.0   \n",
       "9354          393      0  2018-11-14 16:25:32  2018-10-01 00:00:00  32376.0   \n",
       "9353          393      0  2018-11-13 06:05:24  2018-10-01 00:00:00  32376.0   \n",
       "...           ...    ...                  ...                  ...      ...   \n",
       "4596         3918      0  2020-03-27 09:11:56  2020-03-26 23:59:59  12057.6   \n",
       "13637        4159      1  2020-03-27 09:07:24  2020-03-26 23:59:59   2561.0   \n",
       "9019         6111      1  2020-03-27 09:24:57  2020-03-27 23:59:59  44501.0   \n",
       "11165        3227      0  2020-03-28 00:10:37  2020-03-27 23:59:59  33260.0   \n",
       "9020         6111      0  2020-03-27 10:51:34  2020-03-27 23:59:59  44501.0   \n",
       "\n",
       "       priority  qualifier    origin            createdAt reason param  \\\n",
       "6164          2       read  customer  2018-09-25 18:41:11    NaN   NaN   \n",
       "9487          3  estimated       vnb  2018-10-18 11:50:06    COS   SMV   \n",
       "9359          1       read       vnb  2018-10-08 06:30:07    COS   SMV   \n",
       "9354          3  estimated       vnb  2018-11-14 16:25:32    COS   SMV   \n",
       "9353          3  estimated       vnb  2018-11-13 06:05:24    COS   SMV   \n",
       "...         ...        ...       ...                  ...    ...   ...   \n",
       "4596          1       read       msb  2020-03-27 09:11:56    PMR   MRV   \n",
       "13637         1       read       msb  2020-03-27 09:07:24    PMR   MRV   \n",
       "9019          2       read  customer  2020-03-27 09:24:57    NaN   NaN   \n",
       "11165         1       read       vnb  2020-03-28 00:10:37    PMR   MRV   \n",
       "9020          1       read       msb  2020-03-27 10:51:34    COT   MRV   \n",
       "\n",
       "             code         counter  \n",
       "6164    1-1:1.8.0         7796478  \n",
       "9487   7-20:3.0.0           89913  \n",
       "9359   7-20:3.0.0         3322005  \n",
       "9354    1-1:1.8.0    470000340043  \n",
       "9353    1-1:1.8.0    470000340043  \n",
       "...           ...             ...  \n",
       "4596    1-1:1.8.0  1APADA90917567  \n",
       "13637   1-0:1.8.0  1LOG0065083099  \n",
       "9019    1-1:1.8.0      4100186942  \n",
       "11165  7-20:3.0.0          889902  \n",
       "9020    1-1:1.8.0      4100186942  \n",
       "\n",
       "[16526 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze data\n",
    "\n",
    "- What is the meaning of individual columns?\n",
    "- Columns suitable for decision-making? (e.g. too many na-values bad)\n",
    "- Is **data** assumed to be sufficient? If not, start over with **1. Conception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11046\n",
       "0     5480\n",
       "Name: valid, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.g. check total number of valid / invalid readings, 1 or 0, respectively. \n",
    "data[\"valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Data Aggregation Strategy\n",
    "\n",
    "How to group **data** belonging together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by contract, code and counter\n",
    "grouper = [\"contractId\", \"code\", \"counter\"]\n",
    "select = [column for column in data if not column in grouper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = list(group[select] for context, group in data.groupby(grouper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid</th>\n",
       "      <th>validityChangedAt</th>\n",
       "      <th>readAt</th>\n",
       "      <th>value</th>\n",
       "      <th>priority</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>origin</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>reason</th>\n",
       "      <th>param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 20:05:21</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>3848.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-31 20:05:21</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 23:59:59</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>66</td>\n",
       "      <td>estimated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-16 10:16:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-20 10:36:55</td>\n",
       "      <td>2019-02-13 23:59:59</td>\n",
       "      <td>4669.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2019-03-11 08:55:17</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9386</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 11:17:19</td>\n",
       "      <td>2019-09-15 23:59:00</td>\n",
       "      <td>4645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2019-10-14 10:35:56</td>\n",
       "      <td>COM</td>\n",
       "      <td>EMV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      valid    validityChangedAt               readAt   value  priority  \\\n",
       "9384      1  2018-10-31 20:05:21  2018-10-01 00:00:00  3848.0         1   \n",
       "9391      1                  NaN  2018-12-31 23:59:59  4126.0        66   \n",
       "9385      0  2019-12-20 10:36:55  2019-02-13 23:59:59  4669.0         3   \n",
       "9386      1  2019-10-14 11:17:19  2019-09-15 23:59:00  4645.0         1   \n",
       "\n",
       "      qualifier origin            createdAt reason param  \n",
       "9384       read    vnb  2018-10-31 20:05:21    COS   SMV  \n",
       "9391  estimated    NaN  2020-01-16 10:16:05    NaN   NaN  \n",
       "9385  estimated    vnb  2019-03-11 08:55:17    PMR   MRV  \n",
       "9386       read    vnb  2019-10-14 10:35:56    COM   EMV  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated[102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Structure and clean data\n",
    "\n",
    "- Structure **data** so you have a clear view how to clean it\n",
    "- Clean data: Remove insufficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid</th>\n",
       "      <th>validityChangedAt</th>\n",
       "      <th>readAt</th>\n",
       "      <th>value</th>\n",
       "      <th>priority</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>origin</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>reason</th>\n",
       "      <th>param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-10-31 20:05:21</td>\n",
       "      <td>2018-10-01 00:00:00</td>\n",
       "      <td>3848.0</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2018-10-31 20:05:21</td>\n",
       "      <td>COS</td>\n",
       "      <td>SMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 23:59:59</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>66</td>\n",
       "      <td>estimated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-16 10:16:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-20 10:36:55</td>\n",
       "      <td>2019-02-13 23:59:59</td>\n",
       "      <td>4669.0</td>\n",
       "      <td>3</td>\n",
       "      <td>estimated</td>\n",
       "      <td>vnb</td>\n",
       "      <td>2019-03-11 08:55:17</td>\n",
       "      <td>PMR</td>\n",
       "      <td>MRV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      valid    validityChangedAt               readAt   value  priority  \\\n",
       "9384    1.0  2018-10-31 20:05:21  2018-10-01 00:00:00  3848.0         1   \n",
       "9391    1.0                  NaN  2018-12-31 23:59:59  4126.0        66   \n",
       "9385    NaN  2019-12-20 10:36:55  2019-02-13 23:59:59  4669.0         3   \n",
       "\n",
       "      qualifier origin            createdAt reason param  \n",
       "9384       read    vnb  2018-10-31 20:05:21    COS   SMV  \n",
       "9391  estimated    NaN  2020-01-16 10:16:05    NaN   NaN  \n",
       "9385  estimated    vnb  2019-03-11 08:55:17    PMR   MRV  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose past readings from readings for assessment\n",
    "past = []\n",
    "assess = []\n",
    "for x in aggregated:\n",
    "    \n",
    "    # Last item of the row\n",
    "    assess_ = x.iloc[-1]\n",
    "    \n",
    "    # Append n-1 rows from group\n",
    "    past_ = x.iloc[0:-1]\n",
    "    \n",
    "    # Hmm ... unfortunately if have to drop some values\n",
    "    # that have not been available @ decision making time\n",
    "    validity_changed_after_decision = (past_[\"validityChangedAt\"] > assess_[\"readAt\"])\n",
    "    past_[\"valid\"][validity_changed_after_decision] = np.nan\n",
    "    # -> Problem with DB updates! ...\n",
    "    \n",
    "    past.append(past_)\n",
    "    assess.append(assess_)\n",
    "    \n",
    "past[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # Features for predicting\n",
    "y = []\n",
    "\n",
    "select.remove(\"valid\")\n",
    "for past_, assess_ in zip(past, assess):\n",
    "    X.append(assess_[select].tolist() + past_[::-1].values.flatten().tolist())\n",
    "    y.append(assess_[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "# Get matrix shape of X: padding of individual # of past items\n",
    "n_features = 3 * (len(select) + 1) + len(select)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Create training data\n",
    "\n",
    "- Decompose data into feature matrix X and target vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix needs to be 2D in this case. Since # of past readings varies,\n",
    "# some data points need to be dropped, some other need to be padded (with na)\n",
    "Xout = []\n",
    "for Xi in X:\n",
    "    \n",
    "    n = len(Xi)\n",
    "    \n",
    "    if n > n_features:\n",
    "        Xi = Xi[-n_features:]\n",
    "    elif n < n_features:\n",
    "        Xi = Xi + ([np.nan] * (n_features - n))\n",
    "    \n",
    "    Xout.append(Xi)\n",
    "\n",
    "# Feature matrix: Features characterizing the past reading history\n",
    "X = pandas.DataFrame(Xout) \n",
    "# Target vector: Binary vector (1 -> valid, 0 -> invalid)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preparation for machine learning: Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conversion: Features must be floats. Think of how to convert\n",
    "    - dates\n",
    "    - strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn: Library containing a greate number of ML utilities\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion for filtering float-like columns from x\n",
    "def is_float_convertable(x):\n",
    "    \n",
    "    try: \n",
    "        x.astype(float)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Criterion for filtering date-like columns from x\n",
    "def is_datelike(x):\n",
    "    \n",
    "    try:\n",
    "        pandas.to_datetime(x)\n",
    "        \n",
    "        if not is_float_convertable(x):\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously, we have multi-type data available. All types have to be converted into float. \n",
    "# For converting categorical data, there are special encoding methodes available. \n",
    "\n",
    "# Decompose data by type\n",
    "numerical = [column for column in X if is_float_convertable(X[column])]\n",
    "dates = [column for column in X if is_datelike(X[column])]\n",
    "strings = [column for column in X if not column in numerical + dates]\n",
    "\n",
    "# Convert dates to float: Total seconds since millenium\n",
    "null_date = datetime.datetime(2000, 1, 1)\n",
    "for d in dates:\n",
    "    X[d] = (pandas.to_datetime(X[d]) - null_date).dt.total_seconds()\n",
    "    \n",
    "# Convert str columns: One-Hot-Encoding\n",
    "Xstr = X[strings].fillna(\"nan\")\n",
    "Xstr = pandas.DataFrame(OneHotEncoder(sparse=False) \\\n",
    "             .fit_transform(Xstr))\n",
    "X.drop(columns=strings, inplace=True)\n",
    "X.columns = range(len(X.columns))\n",
    "string_columns = np.arange(max(X.columns) + 1, (max(X.columns) + Xstr.shape[1] + 1))\n",
    "X[string_columns] = Xstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- na-fill strategy: Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SimpleImputer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling: Normalize **data** features, such that each have similar impact, e.g. (-1, 1) normalization of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training\n",
    "\n",
    "- Select suitable algorithm\n",
    "- Test if training technically works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn: Library containing a greate number of ML utilities\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Given subset of X, train to be able to predict associated subset y\n",
    "tree.fit(X[0:2300, :], y[0:2300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier prediction for data NOT used for training\n",
    "pred = tree.predict(X[2300:])\n",
    "true = y[2300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measure quality of model: Precision and Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6906474820143885"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96, 36],\n",
       "       [43, 21]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred, true, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Systematic optimization\n",
    "\n",
    "- Algorithms have parameters to be choosen by user: Apply optimization\n",
    "- Split data systematically among different configurations and select the \"best\" model (requires definition of metric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [None, 5, 10, 20, 50],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='precision')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters taken by DecisionTree classifier\n",
    "params = {\"max_depth\" : [None, 5, 10, 20, 50],\n",
    "          \"min_samples_split\" : [2, 5, 10],\n",
    "          \"max_features\" : [\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "# Create data split strategy\n",
    "cv = KFold(5, random_state=42, shuffle=True)\n",
    "\n",
    "# Init grid search for optimum parameters\n",
    "grd = GridSearchCV(tree, params, cv=cv, scoring=\"precision\")\n",
    "\n",
    "# Train on all possible combinations of parameters\n",
    "grd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7899019591680362"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best classifier\n",
    "clf = grd.best_estimator_\n",
    "\n",
    "# Total precision\n",
    "grd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1478,  418],\n",
       "       [ 422,  178]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute total score\n",
    "confusion = []\n",
    "for train, test in cv.split(X):\n",
    "    \n",
    "    clf.fit(X[train], y[train])\n",
    "    \n",
    "    pred = clf.predict(X[test])\n",
    "    \n",
    "    confusion.append(confusion_matrix(pred, y[test], labels=[1, 0]))\n",
    "    \n",
    "confusion = np.array(confusion).sum(axis=0)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Bring to application\n",
    "\n",
    "- Transformer implement: Implement custom preprocessing into transformer class object\n",
    "- Transformer chain: Chain all processing and classification items together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer object: Steps 4. and 5. in one class \n",
    "from utils import CustomPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer chain\n",
    "chain = Pipeline([(\"custom\", CustomPreprocessing()),\n",
    "                  (\"fillna\", SimpleImputer()),\n",
    "                  (\"scale\", RobustScaler()),\n",
    "                  (\"clf\", DecisionTreeClassifier(**clf.get_params()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('custom', CustomPreprocessing()), ('fillna', SimpleImputer()),\n",
       "                ('scale', RobustScaler()),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(max_depth=50, max_features='sqrt'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on complete data set\n",
    "chain.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data from application:\n",
    "file = 1 # Choose from 1 or 2\n",
    "# Two counters belonging to a single contract\n",
    "appl_data = pandas.read_csv(f\"./data/readings_application_{file}.csv\", index_col=0) \\\n",
    "             .sort_values(by=\"readAt\") \\\n",
    "            [data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractId</th>\n",
       "      <th>valid</th>\n",
       "      <th>validityChangedAt</th>\n",
       "      <th>readAt</th>\n",
       "      <th>value</th>\n",
       "      <th>priority</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>origin</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>reason</th>\n",
       "      <th>param</th>\n",
       "      <th>code</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-05-06 17:33:18</td>\n",
       "      <td>2019-02-02 00:00:00</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2019-05-06 17:33:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>8120000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-07 09:54:55</td>\n",
       "      <td>2019-02-02 00:00:00</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>customer</td>\n",
       "      <td>2019-05-07 09:54:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-1:1.8.0</td>\n",
       "      <td>8120000949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contractId  valid    validityChangedAt               readAt   value  \\\n",
       "0      822417    0.0  2019-05-06 17:33:18  2019-02-02 00:00:00  1341.0   \n",
       "0      822417    NaN  2019-05-07 09:54:55  2019-02-02 00:00:00  1391.0   \n",
       "\n",
       "   priority qualifier    origin            createdAt  reason  param  \\\n",
       "0         2      read  customer  2019-05-06 17:33:18     NaN    NaN   \n",
       "0         2      read  customer  2019-05-07 09:54:55     NaN    NaN   \n",
       "\n",
       "        code     counter  \n",
       "0  1-1:1.8.0  8120000949  \n",
       "0  1-1:1.8.0  8120000949  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict validity of readings with valid == nan\n",
    "pred = chain.predict(appl_data)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
